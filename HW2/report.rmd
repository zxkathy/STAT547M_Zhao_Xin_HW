---
title: "HW7 Automating Data-analysis Pipelines"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  github_document
fig_width: 5
fig_height: 3 
---

## Overall flowchart of the assignment

<center>
![](structure.jpeg){
width=120% }
</center>
The above figure shows my dependency relationship of all my files. Note that I didn't include the figures in the structure graph.

##Prework

I make the libreary and some common variables which could be used throughout the project into the `lib.R` file, and use `source()` function to refer and take use of them.

```{r message=FALSE, warning=FALSE}
source("lib.R")
```


##Data Description

The `Forest Fires Dataset` was obtained from [UCI](https://archive.ics.uci.edu/ml/datasets/Forest+Fires). This dataset has 517 observations and 12 features (Ref 1). 


##Data Glance

```{r results='asis'}
forestFire_head <- read.csv("forestFires.csv", header = TRUE, sep = ",") %>%
	head(10)
knitr::kable(forestFire_head, digits = 2, align ="r", padding = 10)
```
 
Detailed description of each feature could be obtained from [here](https://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/forestfires.names).


##Task 1. Perform Exploratory Analysis 

####Reorder the data by month

First, let's show the bar chart of number of forest fires within each month, with `month` unordered. 

<center>
![](unorderedCount.png){
width=60% }
</center>

Then, let's show the bar chart of number of forest fires within each month, with `month` ordered. 

<center>
![](orderedCount.png){
width=60% }
</center>

It shows that August and September are the two months when the forest fires happen the most.

####Sort the month by total burned area within the month

Let's show the bar chart of total burned forest fires area within each month by another way. 

<center>
![](orderedSum.png){
width=60% }
</center>

The above figure sorting the month according to the total burned forest area within that month.	 

```{r results='asis'}
fire_Month_Area_Ordered <- readRDS("fire_Month_Area_Ordered.rds")
knitr::kable(fire_Month_Area_Ordered, digits = 2, align ="r", padding = 10)
```



####Save the reordered dataset for future use and explore the reordered effect

Let's see whether the levels of `ordered_fireDat.rds` is properly ordered.

```{r}
ordered_fireDat <- readRDS("ordered_fireDat.rds")
levels(ordered_fireDat$month)
levels(ordered_fireDat$day)
```


Both variables `month` and `day` are ordered properly, from `jan` to `dec` and from `sun` to `sat`, respectively. Good! We could retrieve that for later use.


##Task 2. Perform Statistical Analyses

Now we are interested to see the how the weekly fire count trend varies by each month.

```{r, results = 'asis'}
fire_Day_Month_head <-
	readRDS("fire_Day_Month.rds") %>%
	head(15)
knitr::kable(fire_Day_Month_head, digits = 2, align ="r", padding = 10)
```

I built the above form of dataframe for the convinience of plotting using `ggplot`.

<center>
![](weeklyTrend.png){
width=80% }
</center>

It could see that the weekly trend have silimar patterns across months. Wednesdays are the day that the forest fire happens least.  

####Fit linear model and obtain the coef.s 

We are now using the `ordered_fireDat` to do some other analysis. 

```{r results='asis'}
bestMonthAnalysis_head <- read.delim("bestMonthAnalysis.tsv") %>%
	head(16)
knitr::kable(bestMonthAnalysis_head, digits = 2, align ="r", padding = 10)
```

I fit a linear model of (area ~ wind) in the above code and see whether I could find any coeff.s of some months that are significantly different from 0.

####Select best month based on whose coefficients' are significant.

```{r results='asis'}
bestMonthRes <- read.delim("bestMonthRes.tsv") 
knitr::kable(bestMonthRes, digits = 2, align ="r", padding = 10)
```

It could be seen that the coefficients of apr are significant, which means are not likely to be 0. In other words, for the dataset belong to apr, there might exist a relationship of area ~ wind. 


##Task 3. Generate Figures

#### Create a figure for each relative humidity levels.

According to the median of relative humidity levels (variable `RH`), I categorize `RH` into two levels, one is below median, one is above median. After that, I did the linear fit and calculate the coefficient estimates. Below is my results:

```{r results='asis'}
coef_FireDat <- read.delim("coefFireDat.tsv") 
knitr::kable(coef_FireDat, digits = 2, align ="r", padding = 10)
```


<center>
![](lmComparison.png){
width=80% }
</center>


From the results of coefficients table and the above graph, there is some linear relationship between fire burned area and the wind speed when the relative humidity level is low.


## Reference

1. P. Cortez and A. Morais. A Data Mining Approach to Predict Forest Fires using Meteorological Data. 
  In J. Neves, M. F. Santos and J. Machado Eds., New Trends in Artificial Intelligence, 
  Proceedings of the 13th EPIA 2007 - Portuguese Conference on Artificial Intelligence, December, 
  Guimaraes, Portugal, pp. 512-523, 2007. APPIA, ISBN-13 978-989-95618-0-9. 
  Available at: http://www.dsi.uminho.pt/~pcortez/fires.pdf
  
  
## Report your process
In this assignment, I practiced using makefile to do the automated data analysis pipelines. In the very beginning, I am quite confused, but after reading [Jenny's tutorials](), I finally understand how it works. During the assignment, I encountered a problem that the makefile doesn't build if I include my last r file into the report, which is `generate_lm_figures.R`. Interestingly, if I ran that file individually, it works fine, but always encounter an error complaining the mutate function is not working within that file. I went to the office hour and Giulio helped me fix that by commenting out code not used for saing files, i.e. the code displaying tables in the R console. I think probably there is a minor difference between regular R file and the R files used for automating data analysis pipelines. 